{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/ai-native-book/docs","tagsPath":"/ai-native-book/docs/tags","isLast":true,"routePriority":-1,"sidebarFilePath":"G:\\ALL HTML PROJECTS\\hackathon\\ai-native-book\\sidebars.js","contentPath":"G:\\ALL HTML PROJECTS\\hackathon\\ai-native-book\\docs","docs":[{"id":"intro","title":"Introduction","description":"Welcome to your Docusaurus project! This is a placeholder page.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/ai-native-book/docs/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"intro","title":"Introduction","sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Module 2: Human Locomotion, Balance, and Control in Humanoid Robotics","permalink":"/ai-native-book/docs/module2/"}},{"id":"module-1/chapter-1","title":"Chapter 1: Introduction to Physical AI and Robotics","description":"The field of robotics has undergone a dramatic transformation, moving from pre-programmed industrial arms to sophisticated autonomous agents capable of learning and adapting. This evolution is largely driven by the integration of Artificial Intelligence (AI), giving rise to what we term \"Physical AI.\" Physical AI refers to intelligent systems that can perceive their environment, make decisions, and execute actions within the physical world, often through embodied forms like robots. This capability extends beyond mere automation; it involves true cognitive functions that allow machines to interact intelligently and flexibly with complex, unstructured environments. This introductory chapter lays the groundwork by defining key terms, tracing historical developments, and outlining the interdisciplinary nature of this rapidly advancing field.","source":"@site/docs/module-1/chapter-1.md","sourceDirName":"module-1","slug":"/module-1/chapter-1","permalink":"/ai-native-book/docs/module-1/chapter-1","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 1: Foundations of Physical AI","permalink":"/ai-native-book/docs/module-1/"},"next":{"title":"Chapter 2: Robot Kinematics and Dynamics","permalink":"/ai-native-book/docs/module-1/chapter-2"}},{"id":"module-1/chapter-2","title":"Chapter 2: Robot Kinematics and Dynamics","description":"To effectively control a robot, one must understand its motion capabilities and how forces affect its movement. This is where robot kinematics and dynamics come into play. These two fundamental areas form the mathematical bedrock for designing, simulating, and controlling physical AI systems, enabling them to execute precise motions and interact dynamically with their environment.","source":"@site/docs/module-1/chapter-2.md","sourceDirName":"module-1","slug":"/module-1/chapter-2","permalink":"/ai-native-book/docs/module-1/chapter-2","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Introduction to Physical AI and Robotics","permalink":"/ai-native-book/docs/module-1/chapter-1"},"next":{"title":"Chapter 3: Sensing and Perception for Robotics","permalink":"/ai-native-book/docs/module-1/chapter-3"}},{"id":"module-1/chapter-3","title":"Chapter 3: Sensing and Perception for Robotics","description":"For a physical AI system to interact intelligently and autonomously with its environment, it must first be able to perceive it accurately and robustly. Sensing and perception are the robot's fundamental gateways to understanding the world around it, its own state, and the presence and behavior of other agents. This process involves two main stages: sensing, which converts physical phenomena into measurable electrical signals, and perception, which interprets these signals to construct a meaningful, actionable representation of the environment. The quality and reliability of these perceptions directly impact a robot's ability to make informed decisions, plan movements, and execute tasks effectively.","source":"@site/docs/module-1/chapter-3.md","sourceDirName":"module-1","slug":"/module-1/chapter-3","permalink":"/ai-native-book/docs/module-1/chapter-3","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Robot Kinematics and Dynamics","permalink":"/ai-native-book/docs/module-1/chapter-2"},"next":{"title":"Chapter 4: Actuation and Control Systems","permalink":"/ai-native-book/docs/module-1/chapter-4"}},{"id":"module-1/chapter-4","title":"Chapter 4: Actuation and Control Systems","description":"Actuation and control systems are the muscle and nervous system of a robot, respectively, translating abstract computational commands into physical motion and ensuring these motions are executed precisely, stably, and safely. Actuators are the components responsible for generating motion or force, while control systems provide the intelligence to regulate these actuators, allowing the robot to perform its intended tasks in a coordinated and effective manner.","source":"@site/docs/module-1/chapter-4.md","sourceDirName":"module-1","slug":"/module-1/chapter-4","permalink":"/ai-native-book/docs/module-1/chapter-4","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Sensing and Perception for Robotics","permalink":"/ai-native-book/docs/module-1/chapter-3"},"next":{"title":"Chapter 5: Introduction to Robot Operating System (ROS)","permalink":"/ai-native-book/docs/module-1/chapter-5"}},{"id":"module-1/chapter-5","title":"Chapter 5: Introduction to Robot Operating System (ROS)","description":"The Robot Operating System (ROS) is not an operating system in the traditional sense, but rather a flexible framework for writing robot software. It is a meta-operating system that provides a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behaviors across a wide variety of robotic platforms. ROS provides OS-like functionality on a heterogeneous computer cluster, including hardware abstraction, device drivers, libraries, visualizers, message-passing, package management, and more. Mastering ROS is often considered a crucial step for anyone venturing into serious robotics development, as it fosters modularity, reusability, and a vibrant open-source community.","source":"@site/docs/module-1/chapter-5.md","sourceDirName":"module-1","slug":"/module-1/chapter-5","permalink":"/ai-native-book/docs/module-1/chapter-5","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Actuation and Control Systems","permalink":"/ai-native-book/docs/module-1/chapter-4"}},{"id":"module-1/index","title":"Module 1: Foundations of Physical AI","description":"This module lays the groundwork for understanding how artificial intelligence is integrated into physical robotic systems, focusing on the core principles that enable robots to interact with their environment.","source":"@site/docs/module-1/index.md","sourceDirName":"module-1","slug":"/module-1/","permalink":"/ai-native-book/docs/module-1/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Responsible Autonomous Systems","permalink":"/ai-native-book/docs/module4/chapter5"},"next":{"title":"Chapter 1: Introduction to Physical AI and Robotics","permalink":"/ai-native-book/docs/module-1/chapter-1"}},{"id":"module2/chapter1","title":"Chapter 1: Gait Generation: Kinematics and Dynamics","description":"1.1 Introduction to Humanoid Gait","source":"@site/docs/module2/chapter1.md","sourceDirName":"module2","slug":"/module2/chapter1","permalink":"/ai-native-book/docs/module2/chapter1","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 2: Human Locomotion, Balance, and Control in Humanoid Robotics","permalink":"/ai-native-book/docs/module2/"},"next":{"title":"Chapter 2: Zero Moment Point (ZMP) Control and Balance","permalink":"/ai-native-book/docs/module2/chapter2"}},{"id":"module2/chapter2","title":"Chapter 2: Zero Moment Point (ZMP) Control and Balance","description":"2.1 Understanding the Zero Moment Point (ZMP)","source":"@site/docs/module2/chapter2.md","sourceDirName":"module2","slug":"/module2/chapter2","permalink":"/ai-native-book/docs/module2/chapter2","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Gait Generation: Kinematics and Dynamics","permalink":"/ai-native-book/docs/module2/chapter1"},"next":{"title":"Chapter 3: Spring-Loaded Inverted Pendulum (SLIP) Models","permalink":"/ai-native-book/docs/module2/chapter3"}},{"id":"module2/chapter3","title":"Chapter 3: Spring-Loaded Inverted Pendulum (SLIP) Models","description":"3.1 Introduction to SLIP Models","source":"@site/docs/module2/chapter3.md","sourceDirName":"module2","slug":"/module2/chapter3","permalink":"/ai-native-book/docs/module2/chapter3","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Zero Moment Point (ZMP) Control and Balance","permalink":"/ai-native-book/docs/module2/chapter2"},"next":{"title":"Chapter 4: Locomotion Planning and Stability Margins","permalink":"/ai-native-book/docs/module2/chapter4"}},{"id":"module2/chapter4","title":"Chapter 4: Locomotion Planning and Stability Margins","description":"4.1 Introduction to Locomotion Planning","source":"@site/docs/module2/chapter4.md","sourceDirName":"module2","slug":"/module2/chapter4","permalink":"/ai-native-book/docs/module2/chapter4","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Spring-Loaded Inverted Pendulum (SLIP) Models","permalink":"/ai-native-book/docs/module2/chapter3"},"next":{"title":"Chapter 5: Real-world Humanoid Walking Systems","permalink":"/ai-native-book/docs/module2/chapter5"}},{"id":"module2/chapter5","title":"Chapter 5: Real-world Humanoid Walking Systems","description":"5.1 Introduction to Humanoid Robotics Platforms","source":"@site/docs/module2/chapter5.md","sourceDirName":"module2","slug":"/module2/chapter5","permalink":"/ai-native-book/docs/module2/chapter5","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 4: Locomotion Planning and Stability Margins","permalink":"/ai-native-book/docs/module2/chapter4"},"next":{"title":"Module 3: Perception and Intelligence in Physical AI Systems","permalink":"/ai-native-book/docs/module3/"}},{"id":"module2/index","title":"Module 2: Human Locomotion, Balance, and Control in Humanoid Robotics","description":"Overview","source":"@site/docs/module2/index.md","sourceDirName":"module2","slug":"/module2/","permalink":"/ai-native-book/docs/module2/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/ai-native-book/docs/intro"},"next":{"title":"Chapter 1: Gait Generation: Kinematics and Dynamics","permalink":"/ai-native-book/docs/module2/chapter1"}},{"id":"module3/chapter1","title":"Computer Vision in Robotics","description":"Computer vision is a crucial component in modern robotics, enabling machines to \"see\" and interpret their environment. In the context of the AI-Robot Brain, computer vision pipelines process raw sensor data from cameras and depth sensors to extract meaningful information for perception, navigation, and manipulation. This chapter explores the fundamentals of computer vision as applied to robotics, with a focus on its integration with NVIDIA Isaac platform components like Isaac ROS.","source":"@site/docs/module3/chapter1.md","sourceDirName":"module3","slug":"/module3/chapter1","permalink":"/ai-native-book/docs/module3/chapter1","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 3: Perception and Intelligence in Physical AI Systems","permalink":"/ai-native-book/docs/module3/"},"next":{"title":"Multimodal Sensing Fusion","permalink":"/ai-native-book/docs/module3/chapter2"}},{"id":"module3/chapter2","title":"Multimodal Sensing Fusion","description":"Robots operating in complex environments benefit significantly from multimodal sensing fusion, which combines data from various sensor types (e.g., cameras, LiDAR, IMUs, depth sensors) to create a more robust and comprehensive understanding of the surroundings. This chapter delves into the principles and techniques behind fusing data from disparate sensors, enhancing a robot's perception capabilities beyond what a single sensor could provide.","source":"@site/docs/module3/chapter2.md","sourceDirName":"module3","slug":"/module3/chapter2","permalink":"/ai-native-book/docs/module3/chapter2","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Computer Vision in Robotics","permalink":"/ai-native-book/docs/module3/chapter1"},"next":{"title":"SLAM & Spatial Understanding","permalink":"/ai-native-book/docs/module3/chapter3"}},{"id":"module3/chapter3","title":"SLAM & Spatial Understanding","description":"Simultaneous Localization and Mapping (SLAM) is a fundamental problem in robotics, enabling a robot to build a map of an unknown environment while simultaneously tracking its own pose (position and orientation) within that map. For AI-powered robots, especially humanoids, robust SLAM and spatial understanding are critical for autonomous navigation, interaction, and task execution. This chapter explores various SLAM techniques and how they contribute to a robot's spatial awareness, with a focus on NVIDIA Isaac ROS integration.","source":"@site/docs/module3/chapter3.md","sourceDirName":"module3","slug":"/module3/chapter3","permalink":"/ai-native-book/docs/module3/chapter3","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Multimodal Sensing Fusion","permalink":"/ai-native-book/docs/module3/chapter2"},"next":{"title":"Sensor Calibration","permalink":"/ai-native-book/docs/module3/chapter4"}},{"id":"module3/chapter4","title":"Sensor Calibration","description":"Accurate sensor data is paramount for robust robotic perception, navigation, and manipulation. Before any meaningful data fusion or SLAM can occur, all sensors on a robot must be carefully calibrated. Sensor calibration is the process of determining the intrinsic and extrinsic parameters of each sensor, ensuring that their measurements are accurate and that their spatial relationships to each other and to the robot's body are precisely known. This chapter details essential sensor calibration techniques for common robotic sensors.","source":"@site/docs/module3/chapter4.md","sourceDirName":"module3","slug":"/module3/chapter4","permalink":"/ai-native-book/docs/module3/chapter4","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"SLAM & Spatial Understanding","permalink":"/ai-native-book/docs/module3/chapter3"},"next":{"title":"AI Reasoning in Robotics Systems","permalink":"/ai-native-book/docs/module3/chapter5"}},{"id":"module3/chapter5","title":"AI Reasoning in Robotics Systems","description":"AI reasoning is the ability of a robot to process information, make decisions, plan actions, and adapt to its environment in an intelligent manner. In the context of the AI-Robot Brain, this involves moving beyond basic perception and control to higher-level cognitive functions that enable autonomous and adaptive behavior. This chapter explores how AI reasoning is applied in robotics, integrating concepts from machine learning, symbolic AI, and cognitive architectures, with a focus on how NVIDIA Isaac platform components facilitate these advanced capabilities.","source":"@site/docs/module3/chapter5.md","sourceDirName":"module3","slug":"/module3/chapter5","permalink":"/ai-native-book/docs/module3/chapter5","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Sensor Calibration","permalink":"/ai-native-book/docs/module3/chapter4"},"next":{"title":"Module 4: Human–Robot Interaction, Safety, and Ethical Robotics","permalink":"/ai-native-book/docs/module4/"}},{"id":"module3/index","title":"Module 3: Perception and Intelligence in Physical AI Systems","description":"Overview","source":"@site/docs/module3/index.md","sourceDirName":"module3","slug":"/module3/","permalink":"/ai-native-book/docs/module3/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: Real-world Humanoid Walking Systems","permalink":"/ai-native-book/docs/module2/chapter5"},"next":{"title":"Computer Vision in Robotics","permalink":"/ai-native-book/docs/module3/chapter1"}},{"id":"module4/chapter1","title":"Human-Robot Interaction Models","description":"Human-Robot Interaction (HRI) is a multidisciplinary field focused on the design, implementation, and evaluation of robotic systems that interact with humans. As robots become more sophisticated and integrated into our daily lives, understanding and optimizing these interactions is crucial for their effective and safe deployment. This chapter explores various models and paradigms of HRI, providing a foundation for designing intuitive and natural interactions between humans and humanoid robots.","source":"@site/docs/module4/chapter1.md","sourceDirName":"module4","slug":"/module4/chapter1","permalink":"/ai-native-book/docs/module4/chapter1","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 4: Human–Robot Interaction, Safety, and Ethical Robotics","permalink":"/ai-native-book/docs/module4/"},"next":{"title":"Voice & Gesture Interfaces","permalink":"/ai-native-book/docs/module4/chapter2"}},{"id":"module4/chapter2","title":"Voice & Gesture Interfaces","description":"Natural and intuitive communication is paramount for seamless human-robot interaction. Voice and gesture interfaces offer powerful modalities for humans to convey commands, intentions, and feedback to robots, moving beyond cumbersome graphical user interfaces or complex programming. This chapter explores the design and implementation of voice and gesture recognition systems for humanoid robots, emphasizing their integration into a cohesive Vision-Language-Action (VLA) pipeline.","source":"@site/docs/module4/chapter2.md","sourceDirName":"module4","slug":"/module4/chapter2","permalink":"/ai-native-book/docs/module4/chapter2","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Human-Robot Interaction Models","permalink":"/ai-native-book/docs/module4/chapter1"},"next":{"title":"Social Robotics & Safety Engineering","permalink":"/ai-native-book/docs/module4/chapter3"}},{"id":"module4/chapter3","title":"Social Robotics & Safety Engineering","description":"As robots become more autonomous and increasingly interact with humans in shared environments, two critical areas come to the forefront: social robotics and safety engineering. Social robotics focuses on designing robots that can engage with humans in a natural and socially acceptable manner, while safety engineering ensures that these interactions are free from harm. This chapter explores the principles behind creating socially intelligent robots and the essential safety protocols and design considerations for human-robot collaboration.","source":"@site/docs/module4/chapter3.md","sourceDirName":"module4","slug":"/module4/chapter3","permalink":"/ai-native-book/docs/module4/chapter3","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Voice & Gesture Interfaces","permalink":"/ai-native-book/docs/module4/chapter2"},"next":{"title":"Ethical Frameworks in Robotics","permalink":"/ai-native-book/docs/module4/chapter4"}},{"id":"module4/chapter4","title":"Ethical Frameworks in Robotics","description":"As humanoid robots become increasingly sophisticated and integrated into society, capable of autonomous decision-making and interaction, the need for robust ethical frameworks becomes paramount. These frameworks provide a principled approach to guide the design, development, deployment, and governance of robotic systems, ensuring they align with human values, societal norms, and legal requirements. This chapter explores key ethical principles and established frameworks relevant to robotics and AI.","source":"@site/docs/module4/chapter4.md","sourceDirName":"module4","slug":"/module4/chapter4","permalink":"/ai-native-book/docs/module4/chapter4","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Social Robotics & Safety Engineering","permalink":"/ai-native-book/docs/module4/chapter3"},"next":{"title":"Responsible Autonomous Systems","permalink":"/ai-native-book/docs/module4/chapter5"}},{"id":"module4/chapter5","title":"Responsible Autonomous Systems","description":"The development of autonomous robotic systems, particularly humanoids with advanced AI capabilities, necessitates a deep commitment to responsibility. This final chapter synthesizes the concepts of human-robot interaction, safety engineering, and ethical frameworks into a comprehensive approach for designing, deploying, and governing responsible autonomous systems. It emphasizes the practical steps and ongoing considerations required to ensure that these powerful technologies serve humanity beneficially and ethically.","source":"@site/docs/module4/chapter5.md","sourceDirName":"module4","slug":"/module4/chapter5","permalink":"/ai-native-book/docs/module4/chapter5","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Ethical Frameworks in Robotics","permalink":"/ai-native-book/docs/module4/chapter4"},"next":{"title":"Module 1: Foundations of Physical AI","permalink":"/ai-native-book/docs/module-1/"}},{"id":"module4/index","title":"Module 4: Human–Robot Interaction, Safety, and Ethical Robotics","description":"Module 4 delves into the critical aspects of human-robot interaction (HRI), ensuring safety in collaborative environments, and addressing the profound ethical considerations that arise with advanced autonomous systems. As robots become more integrated into daily life and take on increasingly complex roles, understanding how to design, deploy, and govern them responsibly becomes paramount.","source":"@site/docs/module4/index.md","sourceDirName":"module4","slug":"/module4/","permalink":"/ai-native-book/docs/module4/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"AI Reasoning in Robotics Systems","permalink":"/ai-native-book/docs/module3/chapter5"},"next":{"title":"Human-Robot Interaction Models","permalink":"/ai-native-book/docs/module4/chapter1"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro"},{"type":"category","label":"Module 2","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"module2/chapter1"},{"type":"doc","id":"module2/chapter2"},{"type":"doc","id":"module2/chapter3"},{"type":"doc","id":"module2/chapter4"},{"type":"doc","id":"module2/chapter5"}],"link":{"type":"doc","id":"module2/index"}},{"type":"category","label":"Module 3","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"module3/chapter1"},{"type":"doc","id":"module3/chapter2"},{"type":"doc","id":"module3/chapter3"},{"type":"doc","id":"module3/chapter4"},{"type":"doc","id":"module3/chapter5"}],"link":{"type":"doc","id":"module3/index"}},{"type":"category","label":"Module 4","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"module4/chapter1"},{"type":"doc","id":"module4/chapter2"},{"type":"doc","id":"module4/chapter3"},{"type":"doc","id":"module4/chapter4"},{"type":"doc","id":"module4/chapter5"}],"link":{"type":"doc","id":"module4/index"}},{"type":"category","label":"Module 1: Foundations of Physical AI","collapsible":true,"collapsed":true,"items":[{"type":"doc","id":"module-1/chapter-1"},{"type":"doc","id":"module-1/chapter-2"},{"type":"doc","id":"module-1/chapter-3"},{"type":"doc","id":"module-1/chapter-4"},{"type":"doc","id":"module-1/chapter-5"}],"link":{"type":"doc","id":"module-1/index"}}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[],"blogListPaginated":[],"blogTags":{},"blogTagsListPath":"/ai-native-book/blog/tags"}},"docusaurus-plugin-content-pages":{"default":null},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-theme-search-algolia":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}