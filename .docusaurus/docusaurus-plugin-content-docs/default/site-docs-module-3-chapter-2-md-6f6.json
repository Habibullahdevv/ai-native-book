{
  "id": "module3/chapter2",
  "title": "Multimodal Sensing Fusion",
  "description": "Robots operating in complex environments benefit significantly from multimodal sensing fusion, which combines data from various sensor types (e.g., cameras, LiDAR, IMUs, depth sensors) to create a more robust and comprehensive understanding of the surroundings. This chapter delves into the principles and techniques behind fusing data from disparate sensors, enhancing a robot's perception capabilities beyond what a single sensor could provide.",
  "source": "@site/docs/module3/chapter2.md",
  "sourceDirName": "module3",
  "slug": "/module3/chapter2",
  "permalink": "/ai-native-book/docs/module3/chapter2",
  "draft": false,
  "unlisted": false,
  "tags": [],
  "version": "current",
  "frontMatter": {},
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Computer Vision in Robotics",
    "permalink": "/ai-native-book/docs/module3/chapter1"
  },
  "next": {
    "title": "SLAM & Spatial Understanding",
    "permalink": "/ai-native-book/docs/module3/chapter3"
  }
}